---
title: "Yanan_apple_analysis_code"
author: "Zhiyao (Yao) Ma"
date: "2025-02-24"
output:
  html_document: 
  mathjax: default
---

```{r setup}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

# Loading the Data

```{r Packages and Loading the Data}
# install.packages("readxl")
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("lmtest")
# install.packages("sandwich")
# install.packages("stargazer")
# install.packages("margins")
# install.packages("xtable")
# install.packages("survival")
# install.packages("tidyr")
# install.packages("fmsb")
# install.packages("gridExtra")
# install.packages("knitr")
# install.packages("ggcorrplot")
# install.packages("kableExtra")
# install.packages("here")
# install.packages("reshape2")
# install.packages("cowplot")
# install.packages("ggrepel")
# install.packages("lme4")



library(readxl)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(lmtest)
library(sandwich)
library(stargazer)
library(margins)
library(survival)
library(tidyr)
library(fmsb)
library(knitr)
library(kableExtra)
library(here)
library(reshape2)
library(cowplot)
library(ggrepel)

# set the working dictionary
## here() 自动定位到项目的根目录, 然后可以构造相对路径,而不需要手动setwd()
## here("..") 这会返回 项目根目录的上一级目录。
setwd(here())

# Read the data
df <- read_excel("data/combined_updated.xlsx")
data <- read_excel("data/combined_updated.xlsx")
```

# Descriptive Statistics

## Pie chart of storage users' type and Radar Information-source Plot

```{r pie chart and radar plot}
# Define softer colors
storage_colors <- c("Not_use" = "#FF9999", "Rent_large" = "#99CCFF", 
                   "Rent_small" = "#99DDAA", "Self_built" = "#D8B5FF")

# Create data for pie chart
storage_counts <- as.data.frame(table(df$cold_storage_usage_type))
colnames(storage_counts) <- c("storage_type", "count")
storage_counts$percentage <- round(storage_counts$count / sum(storage_counts$count) * 100, 1)
storage_counts$label <- paste0(storage_counts$storage_type, "\
", 
                              storage_counts$count, " (", 
                              storage_counts$percentage, "%)")

# Create pie chart
pie_chart <- ggplot(storage_counts, aes(x = "", y = count, fill = storage_type)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  scale_fill_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_void() + theme(legend.position = "none",,
        plot.title = element_text(hjust = 0.5)) +
  geom_text_repel(aes(label = label),  nudge_x = 1, size = 4, show.legend = FALSE) +
  labs(title = "Storage Usage Types")


# Create data for radar plot
# First, calculate the mean of each information source by storage type
info_columns <- c("peer_info", "gov_info", "market_info", "futures_info", "buyer_info")

radar_data <- df %>%
  group_by(cold_storage_usage_type) %>%
  summarise(across(all_of(info_columns), mean, na.rm = TRUE))

# Convert to long format for plotting
radar_long <- melt(radar_data, id.vars = "cold_storage_usage_type", 
                  variable.name = "info_source", value.name = "value")

# Create radar plot
radar_plot <- ggplot(radar_long, aes(x = info_source, y = value, 
                                    group = cold_storage_usage_type, 
                                    color = cold_storage_usage_type)) +
  geom_line(linewidth = 2) +
  geom_point(size = 5) +
  scale_color_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(face = "bold"),
        plot.title = element_text(hjust = 0.5)) +
  labs(title = "Price Information Sources by Storage Type", 
       x = "", y = "") +
  coord_polar() +
  ylim(0, 1)

# Arrange the plots in a grid with the legend at the bottom
combined_plot <- gridExtra::grid.arrange(
  gridExtra::arrangeGrob(pie_chart, radar_plot, ncol = 2),
  heights = c(10, 1)
)

# Save the combined plot
ggsave(here("figures","storage_usage_analysis_soft_colors.png"), combined_plot, width = 12, height = 7)

# Display the combined plot
combined_plot
```

## Table of Summary Statistics

```{r Table of Summary Statistics (tex file)}
# Create a storage user indicator
data$storage_user <- ifelse(data$cold_storage_usage_type == "Not_use", 0, 1)

# Define conversion rates
RMB_to_USD <- 0.14  # Approximate exchange rate: 1 RMB = 0.14 USD
kg_to_pound <- 2.20462  # 1 kg = 2.20462 pounds
mu_to_acre <- 0.1647  # 1 mu = 0.1647 acres

# Identify storage users and non-users
storage_data <- data %>% filter(storage_user == 1)
non_storage_data <- data %>% filter(storage_user == 0)
n_storage <- nrow(storage_data)
n_non_storage <- nrow(non_storage_data)
n_full <- nrow(data)

# Create a function to calculate summary statistics with t-tests
calc_stats_with_ttest <- function(var, storage_data, non_storage_data, convert_type = "none") {
  # Calculate means and SDs with appropriate conversions
  if(convert_type == "mu_to_acre") {
    # Convert mu to acres
    storage_mean <- mean(storage_data[[var]], na.rm = TRUE) * mu_to_acre
    storage_sd <- sd(storage_data[[var]], na.rm = TRUE) * mu_to_acre
    non_storage_mean <- mean(non_storage_data[[var]], na.rm = TRUE) * mu_to_acre
    non_storage_sd <- sd(non_storage_data[[var]], na.rm = TRUE) * mu_to_acre
  } else if(convert_type == "RMB_to_USD") {
    # Convert RMB to USD
    storage_mean <- mean(storage_data[[var]], na.rm = TRUE) * RMB_to_USD
    storage_sd <- sd(storage_data[[var]], na.rm = TRUE) * RMB_to_USD
    non_storage_mean <- mean(non_storage_data[[var]], na.rm = TRUE) * RMB_to_USD
    non_storage_sd <- sd(non_storage_data[[var]], na.rm = TRUE) * RMB_to_USD
  } else if(convert_type == "RMB_kg_to_USD_lb") {
    # Convert RMB/kg to USD/pound
    storage_mean <- mean(storage_data[[var]], na.rm = TRUE) * RMB_to_USD / kg_to_pound
    storage_sd <- sd(storage_data[[var]], na.rm = TRUE) * RMB_to_USD / kg_to_pound
    non_storage_mean <- mean(non_storage_data[[var]], na.rm = TRUE) * RMB_to_USD / kg_to_pound
    non_storage_sd <- sd(non_storage_data[[var]], na.rm = TRUE) * RMB_to_USD / kg_to_pound
  } else {
    # No conversion needed
    storage_mean <- mean(storage_data[[var]], na.rm = TRUE)
    storage_sd <- sd(storage_data[[var]], na.rm = TRUE)
    non_storage_mean <- mean(non_storage_data[[var]], na.rm = TRUE)
    non_storage_sd <- sd(non_storage_data[[var]], na.rm = TRUE)
  }
  
  # Perform t-test with appropriate conversions
  t_test_result <- tryCatch({
    if(convert_type == "mu_to_acre") {
      t.test(storage_data[[var]] * mu_to_acre, non_storage_data[[var]] * mu_to_acre)
    } else if(convert_type == "RMB_to_USD") {
      t.test(storage_data[[var]] * RMB_to_USD, non_storage_data[[var]] * RMB_to_USD)
    } else if(convert_type == "RMB_kg_to_USD_lb") {
      t.test(storage_data[[var]] * RMB_to_USD / kg_to_pound, non_storage_data[[var]] * RMB_to_USD / kg_to_pound)
    } else {
      t.test(storage_data[[var]], non_storage_data[[var]])
    }
  }, error = function(e) {
    # Return NA if t-test fails
    return(list(p.value = NA, statistic = NA))
  })
  
  # Get p-value and t-statistic
  p_value <- t_test_result$p.value
  t_stat <- t_test_result$statistic
  
  # Add significance stars
  sig_stars <- ""
  if(!is.na(p_value)) {
    if(p_value < 0.01) sig_stars <- "***"
    else if(p_value < 0.05) sig_stars <- "**"
    else if(p_value < 0.1) sig_stars <- "*"
  }
  
  return(list(
    storage_mean = storage_mean,
    storage_sd = storage_sd,
    non_storage_mean = non_storage_mean,
    non_storage_sd = non_storage_sd,
    t_stat = t_stat,
    p_value = p_value,
    sig_stars = sig_stars
  ))
}

# Create a dataframe with variable names, labels, and conversion types
variables <- data.frame(
  var_name = c(
    # Panel A: Farmer Demographics
    "age", "hh_size", "labor_size", "education_highest", "family_ever_village_leader","liquidity_constraint",
    # Panel B: Production and Consumption
    "yield_tons", "acres_mu", "bad_ratio", "apple_income", "Income", "labor_cost", "fam_consump",
    # Panel C: Storage and Risk-Related Factors
    "car_track", "nd_insurance", "p_insurance", "CRRA_adjusted", "storage_in_village", 
    "far_to_small_storage", "far_to_large_storage", "storage_purpose_wider_marketing", "storage_purpose_bargaining_tool",
    # Panel D: Marketing
    "highest_price_kg", "ly_good_price_kg", "Wechat_sell", "relatiol_sell", "contract_sell",
    # Panel E: Market Competitive Conditions
    "more_buyers_future", "less_buyers_future", "num_buyers", "subjective_belief_buyer_com"
  ),
  var_label = c(
    # Panel A: Farmer Demographics
    "Age (years)", "Household size (persons)", "Labor size (persons)", "Highest education (level)", 
    "Family ever village leader (0/1)", "Liquidity constrained (0/1)",
    # Panel B: Production and Consumption
    "Apple yield (tons)", "Land size (acre)", "Bad apple ratio", "Apple income (USD)", 
    "Total income (USD)", "Labor cost (USD)", "Family consumption (USD)",
    # Panel C: Storage and Risk-Related Factors
    "Car/truck ownership (0/1)", "Natural disaster insurance (0/1)", "Price insurance (0/1)", 
    "CRRA adjusted (coef)", "Storage in village (0/1)", "Far to small storage (0/1)", 
    "Far to large storage (0/1)", "Storage for wider marketing (0/1)", "Storage as bargaining tool (0/1)",
    # Panel D: Marketing
    "Highest price per pound (USD/lb)", "Good price per pound (USD/lb)", 
    "WeChat selling (0/1)", "Relational selling (0/1)", "Contract selling (0/1)",
    # Panel E: Market Competitive Conditions
    "Expect more buyers (0/1)", "Expect fewer buyers (0/1)", 
    "Number of buyers at harvest (count)", "Subjective buyer competitiveness (1/5)"
  ),
  panel = c(
    rep("Panel A: Farmer Demographics", 6),
    rep("Panel B: Production and Consumption", 7),
    rep("Panel C: Storage and Risk-Related Factors", 9),
    rep("Panel D: Marketing", 5),
    rep("Panel E: Market Competitive Conditions", 4)
  ),
  convert_type = c(
    # Panel A: Farmer Demographics
    rep("none", 6),
    # Panel B: Production and Consumption
    "none", "mu_to_acre", "none", "RMB_to_USD", "RMB_to_USD", "RMB_to_USD", "RMB_to_USD",
    # Panel C: Storage and Risk-Related Factors
    rep("none", 9),
    # Panel D: Marketing
    "RMB_kg_to_USD_lb", "RMB_kg_to_USD_lb", rep("none", 3),
    # Panel E: Market Competitive Conditions
    rep("none", 4)
  )
)

# Create an empty dataframe to store results
results <- data.frame(
  Panel = character(),
  Variable = character(),
  Storage_Mean = numeric(),
  Storage_SD = numeric(),
  Non_Storage_Mean = numeric(),
  Non_Storage_SD = numeric(),
  T_Stat = numeric(),
  P_Value = numeric(),
  Sig_Stars = character(),
  stringsAsFactors = FALSE
)

# Calculate statistics for each variable
for(i in 1:nrow(variables)) {
  var <- variables$var_name[i]
  
  # Skip if variable doesn't exist in the dataset
  if(!var %in% colnames(data)) {
    cat("Variable not found:", var, "\
")
    next
  }
  
  # Calculate statistics
  stats <- calc_stats_with_ttest(
    var, storage_data, non_storage_data, 
    convert_type = variables$convert_type[i]
  )
  
  # Add to results dataframe
  results <- rbind(results, data.frame(
    Panel = variables$panel[i],
    Variable = variables$var_label[i],
    Storage_Mean = stats$storage_mean,
    Storage_SD = stats$storage_sd,
    Non_Storage_Mean = stats$non_storage_mean,
    Non_Storage_SD = stats$non_storage_sd,
    T_Stat = stats$t_stat,
    P_Value = stats$p_value,
    Sig_Stars = stats$sig_stars,
    stringsAsFactors = FALSE
  ))
}


# Create a summary table without pack_rows to avoid header mismatch
results_table <- results %>%
  mutate(
    Storage_Mean_Formatted = sprintf("%.2f", Storage_Mean),
    Storage_SD_Formatted = sprintf("%.2f", Storage_SD),
    Non_Storage_Mean_Formatted = sprintf("%.2f", Non_Storage_Mean),
    Non_Storage_SD_Formatted = sprintf("%.2f", Non_Storage_SD),
    T_Stat_Formatted = paste0(sprintf("%.2f", T_Stat), Sig_Stars)
  ) %>%
  select(Panel, Variable, Storage_Mean_Formatted, Storage_SD_Formatted, 
         Non_Storage_Mean_Formatted, Non_Storage_SD_Formatted, T_Stat_Formatted)

print(results_table)



# Format the results for LaTeX output
results_latex <- results %>%
  mutate(
    Storage_Mean_Stars = sprintf("%.2f", Storage_Mean),
    Storage_SD = sprintf("(%.2f)", Storage_SD),
    Non_Storage_Mean = sprintf("%.2f", Non_Storage_Mean),
    Non_Storage_SD = sprintf("(%.2f)", Non_Storage_SD),
    T_Stat = paste0(sprintf("%.2f", T_Stat), Sig_Stars)
  ) %>%
  select(Panel, Variable, Storage_Mean_Stars, Storage_SD, Non_Storage_Mean, Non_Storage_SD, T_Stat)

# Group by panel
panels <- unique(results_latex$Panel)

# Create the LaTeX file
latex_output <- "\\begin{table}[H]\
\\centering\
\\caption{Summary Statistics by Storage Usage}\
\\label{tab: summary statistics}\
\\resizebox{\\textwidth}{!}{%\
"

latex_output <- paste0(latex_output, "\\begin{tabular}{lccccc}\
\\toprule\
")
latex_output <- paste0(latex_output, " & \\multicolumn{2}{c}{Storage Users} & \\multicolumn{2}{c}{Non-Users} & Difference \\\\\
")
latex_output <- paste0(latex_output, "\\cmidrule(lr){2-3} \\cmidrule(lr){4-5}\
")
latex_output <- paste0(latex_output, "Variable & Mean & SD & Mean & SD & t-statistic \\\\\
\\midrule\
")

# Add each panel with its variables
for(panel in panels) {
  panel_data <- results_latex %>% filter(Panel == panel)
  
  # Add panel header
  latex_output <- paste0(latex_output, "\\multicolumn{6}{l}{\\textbf{", panel, "}} \\\\\
")
  
  # Add variables for this panel
  for(i in 1:nrow(panel_data)) {
    latex_output <- paste0(latex_output, 
                          panel_data$Variable[i], " & ", 
                          panel_data$Storage_Mean_Stars[i], " & ", 
                          panel_data$Storage_SD[i], " & ", 
                          panel_data$Non_Storage_Mean[i], " & ", 
                          panel_data$Non_Storage_SD[i], " & ", 
                          panel_data$T_Stat[i], " \\\\\
")
  }
  
  # Add a small space after each panel except the last one
  if(panel != panels[length(panels)]) {
    latex_output <- paste0(latex_output, "\\addlinespace\
")
  }
}

# Add footer
latex_output <- paste0(latex_output, "\\hline\
\\hline\
Observations & 200 & & 349 & & 549 \\\\\
\\bottomrule\
")


latex_output <- paste0(latex_output, "\\end{tabular}% \n",
"} % End of resizebox \n",
"\\begin{tablenotes} \n",
"\\item \\textit{Notes:} The table presents means and standard deviations (in parentheses) for each variable by group. ",
"T-statistics from two-sample t-tests are reported to indicate statistical significance of differences between groups. ",
"Significance levels are denoted by asterisks: * p$<$0.1, ** p$<$0.05, *** p$<$0.01. ",
"In addition, monetary values have been converted from Chinese Yuan (RMB) to US Dollars (USD), ",
"land area from mu to acres, and apple prices from RMB/kg to USD/pound using appropriate conversion rates. \n",
"\\end{tablenotes} \n",
"\\end{table}"
)


# Write to file
writeLines(latex_output, con = here("tables", "summary_statistics.tex"))
```

## Demographics by storage type

```{r Demographics by storage type}
# Filter and summarize the data for visualization
# Focus on age, education, vehicle ownership (car/truck), CRRA-adjusted values, relational sales, and contractual sales

# Summarize the data by storage type
summary_data <- df %>% 
  group_by(cold_storage_usage_type) %>% 
  summarise(
    avg_age = mean(age, na.rm = TRUE),
    avg_education = mean(education_highest, na.rm = TRUE),
    car_truck_ownership = mean(car_track, na.rm = TRUE),
    avg_crra = mean(CRRA_adjusted, na.rm = TRUE),
    avg_relational_sales = mean(relatiol_sell, na.rm = TRUE),
    avg_contractual_sales = mean(contract_sell, na.rm = TRUE)
  )

print(summary_data)

# Define individual plots
plot_age <- ggplot(summary_data, aes(x = cold_storage_usage_type, y = avg_age, fill = cold_storage_usage_type)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_minimal() +
  labs(title = "Average Age", x = "Storage Type", y = "Age") +
  theme(legend.position = "none")

plot_education <- ggplot(summary_data, aes(x = cold_storage_usage_type, y = avg_education, fill = cold_storage_usage_type)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_minimal() +
  labs(title = "Average Education", x = "Storage Type", y = "Education Level") +
  theme(legend.position = "none")

plot_vehicle <- ggplot(summary_data, aes(x = cold_storage_usage_type, y = car_truck_ownership, fill = cold_storage_usage_type)) +
  geom_bar(stat = "identity") +
    scale_fill_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_minimal() +
  labs(title = "Vehicle Ownership", x = "Storage Type", y = "Ownership Rate") +
  theme(legend.position = "none")

plot_crra <- ggplot(summary_data, aes(x = cold_storage_usage_type, y = avg_crra, fill = cold_storage_usage_type)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_minimal() +
  labs(title = "CRRA-Adjusted", x = "Storage Type", y = "CRRA Value") +
  theme(legend.position = "none")

plot_relational <- ggplot(summary_data, aes(x = cold_storage_usage_type, y = avg_relational_sales, fill = cold_storage_usage_type)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_minimal() +
  labs(title = "Relational Sales", x = "Storage Type", y = "Sales Rate") +
  theme(legend.position = "none")

plot_contractual <- ggplot(summary_data, aes(x = cold_storage_usage_type, y = avg_contractual_sales, fill = cold_storage_usage_type)) +
  geom_bar(stat = "identity") +
    scale_fill_manual(values = storage_colors, name = "Storage Usage Type") +
  theme_minimal() +
  labs(title = "Contractual Sales", x = "Storage Type", y = "Sales Rate") +
  theme(legend.position = "none")

# Combine plots into a grid with shared legend
combined_plot <- grid.arrange(
  arrangeGrob(plot_age, plot_education, plot_vehicle, nrow = 1),
  arrangeGrob(plot_crra, plot_relational, plot_contractual, nrow = 1),
  nrow = 2
)

# Save the combined plot to a file
ggsave(here("figures", "combined_storage_metrics.png"), combined_plot, width = 12, height = 8)
```

## Apple Selling Price by Month and Storage Type

```{r Selling Price by Month and Storage Type}
# Check NA values in selling_month
print("Number of NA values in selling_month:")
print(sum(is.na(df$selling_month)))

# Display some rows where selling_month is NA
print("\
Sample of rows where selling_month is NA:")
print(head(df[is.na(df$selling_month), c("selling_month", "ly_good_price_kg", "cold_storage_usage_type")]))

# Let's clean the data by removing rows where either selling_month or ly_good_price_kg is NA
df_clean <- df %>%
  filter(!is.na(selling_month) & !is.na(ly_good_price_kg))

# Extract month
df_clean$selling_month <- format(df_clean$selling_month, "%m")


# Constants for conversion
yuan_to_dollar = 0.139  # 1 Yuan = 0.139 USD (approximate rate)
kg_to_pound = 2.20462  # 1 kg = 2.20462 pounds

# Convert price from Yuan/kg to Dollar/pound
df_clean$price_dollar_pound <- (df_clean$ly_good_price_kg * yuan_to_dollar) / kg_to_pound

# Calculate frequency for bubble size with converted price
freq_data <- df_clean %>%
  group_by(selling_month, price_dollar_pound, cold_storage_usage_type) %>%
  summarise(count = n(), .groups = 'drop')


# Create the improved bubble plot
p <- ggplot(freq_data, aes(x=selling_month, y=price_dollar_pound, 
                      size=count, color=cold_storage_usage_type)) +
  geom_point(alpha=0.6) +
  scale_color_manual(values = c("Not_use" = "#FF9999", "Rent_large"= "#99CCFF", "Rent_small" = "#99DDAA", "Self_built" = "#D8B5FF")) +
  scale_size(range = c(3, 15)) +
  labs(title="Apple Selling Price by Month and Storage Type",
       x="Selling Month",
       y="Price (USD/lb)",
       size="Number of Observations",
color = "Storage Usage Type") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold"),
    legend.position="right",
    legend.title = element_text(size = 20),
    legend.text = element_text(size = 18),
    axis.text = element_text(size = 18),
    axis.title = element_text(size = 20),
    panel.border = element_rect(color = "black", fill = NA, size = 1)
  )

# Save the plot
ggsave(here("figures", "apple_price_bubble_plot.png"), p, width = 12, height = 8, dpi = 300)

# Display the plot
print(p)

# Updated summary statistics with Dollar/pound
summary_stats <- df_clean %>%
  group_by(cold_storage_usage_type) %>%
  summarise(
    mean_price_usd_lb = mean(price_dollar_pound, na.rm=TRUE),
    sd_price_usd_lb = sd(price_dollar_pound, na.rm=TRUE),
    median_price_usd_lb = median(price_dollar_pound, na.rm=TRUE),
    n_observations = n()
  )

print("\
Updated Summary Statistics by Storage Type (USD/lb):")
print(summary_stats)

# Updated monthly average prices in USD/lb
monthly_avg <- df_clean %>%
  group_by(selling_month) %>%
  summarise(
    mean_price_usd_lb = mean(price_dollar_pound, na.rm=TRUE),
    n_observations = n()
  ) %>%
  arrange(selling_month)

print("\
Updated Monthly Average Prices (USD/lb):")
print(monthly_avg)
```

## Selling Weeks (months) Distribution by Storage Type

```{r Selling Weeks Distribution by Storage Type}
# Create a function to convert dates to week labels
create_week_labels <- function(date) {
    month <- format(date, "%B")
    week_labels <- case_when(
        month == "October" ~ "1 to 4",
        month == "November" ~ "5 to 8",
        month == "December" ~ "9 to 12",
        TRUE ~ "13 to 28"
    )
    return(week_labels)
}

# Convert selling_month and create week labels
df$selling_month <- as.POSIXct(df$selling_month, origin="1970-01-01")
df$week_label <- create_week_labels(df$selling_month)

# Order the week labels correctly
df$week_label <- factor(df$week_label, 
                       levels = c("1 to 4", "5 to 8", "9 to 12", "13 to 28"))

# Create distribution plot by storage type
storage_dist <- ggplot(df, aes(x = week_label, fill = cold_storage_usage_type)) +
  geom_bar(position = "dodge") +
  theme(text = element_text(size = 16)) +
  labs(title = "Distribution of 'Time to Sell'",
       x = "Weeks after Harvest",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 0),,
        plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("Not_use" = "#FF9999", "Rent_large"= "#99CCFF", "Rent_small" = "#99DDAA", "Self_built" = "#D8B5FF")) +
  labs(fill = "Storage Type")

# Save the plot
ggsave(here("figures", "selling_weeks_distribution.png"), storage_dist, width = 12, height = 5, dpi = 300)
storage_dist
```

# Binary Storage Decisions: Buyers’ Competitiveness at Harvest

```{r logit analysis}
data <- read_excel(here("data","combined_updated.xlsx"))
# Ensure necessary libraries for logistic regression and fixed effects are loaded

library(lme4)

# Convert relevant variables to factors or numeric as needed
data$storage_usage_binary <- as.factor(data$storage_usage_binary)
data$town <- as.factor(data$town)
data$family_ever_village_leader <- as.factor(data$family_ever_village_leader)
data$liquidity_constraint <- as.factor(data$liquidity_constraint)
data$education_highest <- as.numeric(data$education_highest)
data$num_buyers <- as.numeric(data$num_buyers)
data$subjective_belief_buyer_com <- as.numeric(data$subjective_belief_buyer_com)
data$CRRA_adjusted <- as.numeric(data$CRRA_adjusted)
data$age <- as.numeric(data$age)

# Model 1: num_buyers only
model1 <- glmer(storage_usage_binary ~ num_buyers + age + education_highest + family_ever_village_leader + CRRA_adjusted + liquidity_constraint +  (1 | town), 
                data = data, family = binomial)

# Model 2: subjective_belief_buyer_com only
model2 <- glmer(storage_usage_binary ~ subjective_belief_buyer_com + age + education_highest + family_ever_village_leader + CRRA_adjusted + liquidity_constraint + (1 | town), 
                data = data, family = binomial)

# Model 3: Both variables
model3 <- glmer(storage_usage_binary ~ num_buyers + subjective_belief_buyer_com + age + education_highest + family_ever_village_leader + CRRA_adjusted + liquidity_constraint + (1 | town), 
                data = data, family = binomial)

# Model 4: Both variables with interaction term
model4 <- glmer(storage_usage_binary ~ num_buyers * subjective_belief_buyer_com + age + education_highest + family_ever_village_leader + CRRA_adjusted + liquidity_constraint + (1 | town), 
                data = data, family = binomial)

# Extract coefficients and standard errors
models_list <- list(model1, model2, model3)


# Create LaTeX table
stargazer(models_list,
          type = "text",
          label = "tab: binary storage ~ buyers' competition at harvest",
          out = here("tables", "buyer's_competition_logistic_results.tex"),
          title = "Logistic Regression Results",
          column.labels = c("Model 1", "Model 2", "Model 3"),
          covariate.labels = c("Number of Buyers",
                             "Subjective Belief",
                             "Age",
                             "Education Level",
                             "Family Village Leader",
                             "CRRA Adjusted",
                             "Liquidity Constrained", 
                             "Constant"),
          dep.var.labels = "Storage Usage (Binary)",
          model.numbers = TRUE,
          single.row = FALSE,
          digits = 2,
          font.size = "footnotesize",
          add.lines = list(c("Town Fixed Effects", "Yes", "Yes", "Yes", "Yes")))
```

```{r Table of Marginal Effects}
# Calculate average marginal effects by using Model 3 
marg_effects <- margins(model3)

# Summary of marginal effects
summary_marg <- summary(marg_effects)

# Create a data frame with the marginal effects for the main predictors
me_table <- data.frame(
  Variable = summary_marg$factor,
  AME = summary_marg$AME,
  SE = summary_marg$SE,
  z_value = summary_marg$z,
  p_value = summary_marg$p
)

# Add significance stars
me_table$Significance <- ifelse(me_table$p_value < 0.01, "***",
                           ifelse(me_table$p_value < 0.05, "**",
                           ifelse(me_table$p_value < 0.1, "*", "")))

# Format numbers to 3 decimal places
me_table$AME <- sprintf("%.3f", me_table$AME)
me_table$SE <- sprintf("%.3f", me_table$SE)
me_table$z_value <- sprintf("%.3f", me_table$z_value)
me_table$p_value <- sprintf("%.3f", me_table$p_value)

# Combine AME and SE for display
me_table$`AME (SE)` <- paste0(me_table$AME, " (", me_table$SE, ")")

# Final table for display
final_table <- me_table[, c("Variable", "AME (SE)", "z_value", "p_value", "Significance")]


# Keep only Variable and AME (SE) columns, and append significance to AME (SE)
final_table$`AME (SE)` <- paste0(final_table$`AME (SE)`, " ", final_table$Significance)
final_table <- final_table[, c("Variable", "AME (SE)")]

# Rename variables
variable_names <- c("num_buyers" = "Number of Buyers at harvest",
  "subjective_belief_buyer_com" = "Subjective Belief on Buyer Competition",
                    "age" = "Age",
                    "education_highest" = "Highest Education",
                    "family_ever_village_leader1" = "Family Ever Village Leader",
                    "CRRA_adjusted" = "CRRA Adjusted",
                    "liquidity_constraint1" = "Liquidity Constrained")

final_table$Variable <- variable_names[final_table$Variable]

# Define the desired order
variable_order <- c("Number of Buyers at harvest", "Subjective Belief on Buyer Competition", "Age", "Highest Education", 
                    "Family Ever Village Leader", "CRRA Adjusted", "Liquidity Constrained")

# Reorder the rows based on the specified variable order
final_table <- final_table[match(variable_order, final_table$Variable), ]


# Using stargazer to produce LaTeX code from our data frame
stargazer(final_table, summary = FALSE, header = FALSE, rownames = FALSE,
          type = "text",
          out = here("tables", "buyer's_competition_logistic_results_AME.tex"),
          title = "Average Marginal Effects from Logistic Regression (Model 3)",
          label = "tab:marginal_effects_model3",
          align = FALSE, 
          font.size = "footnotesize",
          notes = "Note: *p$<$0.1; **p$<$0.05; ***p$<$0.01")
```

```{r interaction effect and plotting}
# Extract coefficient estimates and variance-covariance matrix from model4
coef_est <- fixef(model4)
vcov_mat <- vcov(model4)

# For clarity, assign coefficients from Model 4
# Here:
# beta1: num_buyers, beta2: subjective_belief_buyer_com, beta3: interaction
beta1 <- coef_est['num_buyers']
beta2 <- coef_est['subjective_belief_buyer_com']
beta3 <- coef_est['num_buyers:subjective_belief_buyer_com']

# For each observation, compute linear predictor and predicted probability
linpred <- predict(model4, re.form=NA)  
pred_prob <- 1/(1+exp(-linpred))

# Compute logistic density f(z) and its derivative factor f'(z)
# f(z) = exp(-z)/(1+exp(-z))^2 = dF/dz
f_z <- exp(-linpred)/(1+exp(-linpred))^2

# According to Ai and Norton (2003): the cross partial derivative of P wrt x1 and x2 is:
# d^2P/(dx1 dx2) = f(z)*beta3 + f(z)*(1-2*F(z))*( (beta1 + beta3*x2) * (beta2 + beta3*x1) )
# Here x1 = num_buyers, x2 = subjective_belief_buyer_com
x1 <- data$num_buyers
x2 <- data$subjective_belief_buyer_com

interaction_effect <- f_z * beta3 + f_z * (1 - 2*pred_prob) * ((beta1 + beta3*x2) * (beta2 + beta3*x1))

# We now need to get standard errors for the interaction effect using simulation of the coefficients
# We'll simulate 1000 draws from the multivariate normal distribution of coefficients
library(MASS)
set.seed(1234)
nsim <- 1000
sim_coefs <- mvrnorm(n = nsim, mu = coef_est, Sigma = vcov_mat)

# Compute simulated interaction effects for each observation
sim_interaction <- matrix(NA, nrow=length(x1), ncol=nsim)

for(sim in 1:nsim){
  sim_beta1 <- sim_coefs[sim, 'num_buyers']
  sim_beta2 <- sim_coefs[sim, 'subjective_belief_buyer_com']
  sim_beta3 <- sim_coefs[sim, 'num_buyers:subjective_belief_buyer_com']
  sim_effect <- f_z * sim_beta3 + f_z * (1 - 2*pred_prob) * ((sim_beta1 + sim_beta3*x2) * (sim_beta2 + sim_beta3*x1))
  sim_interaction[,sim] <- sim_effect
}

# Compute standard error as the standard deviation across simulations for each observation
se_interaction <- apply(sim_interaction, 1, sd)

# Create a data frame with predicted probability, interaction effect, and its standard error
df_plot <- data.frame(pred_prob = pred_prob, interaction_effect = interaction_effect, se = se_interaction)

# For visualization, we can smooth the relationship using lowess
smooth_df <- as.data.frame(lowess(df_plot$pred_prob, df_plot$interaction_effect, f = 0.3))
colnames(smooth_df) <- c('pred_prob', 'interaction_effect')

# Plot: x-axis = predicted probability; y-axis = interaction effect
p <- ggplot(df_plot, aes(x = pred_prob, y = interaction_effect)) + 
  geom_point(alpha = 0.5) +
  geom_errorbar(aes(ymin = interaction_effect - 1.96*se, ymax = interaction_effect + 1.96*se), alpha = 0.2) +
  geom_line(data = smooth_df, color = '#009933', size = 1) +
  labs(x = 'Predicted Probability of Storage Usage', y = 'Interaction Effect (Cross Partial Derivative)',
       title = 'Interaction Effect Variation across Predicted Probabilities') +
  theme_minimal()

print(p)

# Save the updated plot to a file
ggsave(filename = here("figures", "Interaction_Effect_across_Predicted Probabilities.png"), plot = p, width = 12, height = 7, dpi = 300)

# Acknowledge that this plot shows how the marginal effect of the interaction term varies by observation
```

# Binary Storage Decisions: Farmers' Expectations on Buyers' Competitiveness

```{r}
# ReLoad the data
data <- read_excel(here("data","combined_updated.xlsx"))

# Convert "expected_number_of_buyers_in_3_months" to a categorical variable
data <- data %>%
  mutate(expect_3_months = case_when(
    expected_number_of_buyers_in_3_months == -1 ~ "fewer_buyers",
    expected_number_of_buyers_in_3_months == 0 ~ "no_change",
    expected_number_of_buyers_in_3_months == 1 ~ "more_buyers"
  ))

# Ensure "expect_3_months" is a factor with "no_change" as the baseline
data$expect_3_months <- factor(data$expect_3_months, levels = c("no_change", "fewer_buyers", "more_buyers"))

# Prepare the formula for the logistic regression
formula_base <- storage_usage_binary ~ expect_3_months + age + education_highest + family_ever_village_leader + CRRA_adjusted + liquidity_constraint + factor(town)
formula_with_additional <- update(formula_base, . ~ . + num_buyers + subjective_belief_buyer_com)

# Run the logistic regressions
model_base <- glm(formula_base, data = data, family = binomial)
model_with_additional <- glm(formula_with_additional, data = data, family = binomial)

# Create a combined table of results
stargazer(model_base, model_with_additional, 
          type = "text",
          omit = "town",
          title = "Logit Analysis: Farmers' Expectations on Buyer Competition in Three Months",
          label = "tab: binary storage ~ farmer's expectation on movement",
          add.lines = list(c("Town Fixed Effects", "Yes", "Yes")),
          out = here("tables", "farmer_expectations_logistic_results.tex"),
          dep.var.labels = "Storage Usage (Binary)",
          covariate.labels = c("Fewer Buyers", "More Buyers", "Age", "Education", "Family Leader", "CRRA Adjusted", "Liquidity Constrained", "Num Buyers", "Subjective Belief"),
          digits = 2, 
          font.size = "footnotesize", 
          star.cutoffs = c(0.05, 0.01, 0.001)
          )

# Calculate marginal effects for "expect_3_months"
marginal_effects <- margins(model_base, variables = "expect_3_months")
summary_marginal_effects <- summary(marginal_effects)

# Save marginal effects to a file
write.csv(summary_marginal_effects, here("tables", "marginal_effects_expect_3_months.csv"))
```

```{r Table of Marginal Effects}
# Calculate average marginal effects by using Model 3 
marg_effects <- margins(model_with_additional)

# Summary of marginal effects
summary_marg <- summary(marg_effects)

# Create a data frame with the marginal effects for the main predictors
me_table <- data.frame(
  Variable = summary_marg$factor,
  AME = summary_marg$AME,
  SE = summary_marg$SE,
  z_value = summary_marg$z,
  p_value = summary_marg$p
)

# Add significance stars
me_table$Significance <- ifelse(me_table$p_value < 0.01, "***",
                           ifelse(me_table$p_value < 0.05, "**",
                           ifelse(me_table$p_value < 0.1, "*", "")))

# Format numbers to 3 decimal places
me_table$AME <- sprintf("%.3f", me_table$AME)
me_table$SE <- sprintf("%.3f", me_table$SE)
me_table$z_value <- sprintf("%.3f", me_table$z_value)
me_table$p_value <- sprintf("%.3f", me_table$p_value)

# Combine AME and SE for display
me_table$`AME (SE)` <- paste0(me_table$AME, " (", me_table$SE, ")")

# Final table for display
final_table <- me_table[, c("Variable", "AME (SE)", "z_value", "p_value", "Significance")]


# Keep only Variable and AME (SE) columns, and append significance to AME (SE)
final_table$`AME (SE)` <- paste0(final_table$`AME (SE)`, " ", final_table$Significance)
final_table <- final_table[, c("Variable", "AME (SE)")]


# Rename variables
variable_names <- c("num_buyers" = "Number of Buyers at harvest",
  "subjective_belief_buyer_com" = "Subjective Belief on Buyer Competition",
                    "age" = "Age",
                    "education_highest" = "Highest Education",
                    "family_ever_village_leader" = "Family Ever Village Leader",
                    "CRRA_adjusted" = "CRRA Adjusted",
                    "liquidity_constraint" = "Liquidity Constrained",
                    "expect_3_monthsfewer_buyers" = "Expect Fewer Buyers",
                    "expect_3_monthsmore_buyers" = "Expect More Buyers"
  )

final_table$Variable <- variable_names[final_table$Variable]

# Define the desired order
variable_order <- c("Expect Fewer Buyers", "Expect More Buyers", "Number of Buyers at harvest", "Subjective Belief on Buyer Competition", "Age", "Highest Education", 
                    "Family Ever Village Leader", "CRRA Adjusted", "Liquidity Constrained")

# Reorder the rows based on the specified variable order
final_table <- final_table[match(variable_order, final_table$Variable), ]


# Using stargazer to produce LaTeX code from our data frame
stargazer(final_table, summary = FALSE, header = FALSE, rownames = FALSE,
          type = "text",
          title = "Average Marginal Effects: Farmers' Expectations on Buyer Competition in Three Months",
          out = here("tables", "farmer_expectations_logistic_results_AME.tex"),
          label = "tab: binary storage ~ farmer's expectation on movement (AME)",
          align = FALSE, 
          font.size = "footnotesize",
          notes = "Note: *p$<$0.1; **p$<$0.05; ***p$<$0.01")
```

```{r predicted probability from the model}
# Get mean values for continuous variables
mean_age <- mean(data$age, na.rm = TRUE)
mean_education <- mean(data$education_highest, na.rm = TRUE)
mean_crra <- mean(data$CRRA_adjusted, na.rm = TRUE)

# Get unique values for categorical variables
unique_towns <- unique(data$town)
unique_family_leader <- unique(data$family_ever_village_leader)
unique_liquidity_constraint <- unique(data$liquidity_constraint)

# Create a comprehensive prediction dataset covering all combinations
newdata <- expand.grid(
  expect_3_months = c("no_change", "fewer_buyers", "more_buyers"),
  age = mean_age,
  education_highest = mean_education,
  family_ever_village_leader = unique_family_leader,
  CRRA_adjusted = mean_crra,
  liquidity_constraint = unique_liquidity_constraint,
  town = unique_towns
)

# Calculate predicted probabilities
newdata$predicted_prob <- predict(model_base, newdata, type = "response")


# Calculate average predicted probabilities by expected buyers and family leadership
avg_probs <- newdata %>%
  group_by(expect_3_months, family_ever_village_leader) %>%
  summarize(avg_prob = mean(predicted_prob, na.rm = TRUE),
            .groups = 'drop')

# Calculate average predicted probabilities by expected buyers and town
avg_probs_town <- newdata %>%
  group_by(expect_3_months, town) %>%
  summarize(avg_prob = mean(predicted_prob, na.rm = TRUE),
            .groups = 'drop')

# Calculate overall average predicted probabilities by expected buyers
overall_avg_probs <- newdata %>%
  group_by(expect_3_months) %>%
  summarize(avg_prob = mean(predicted_prob, na.rm = TRUE),
            .groups = 'drop')

# Print the results
print("Average Predicted Probabilities by Expected Buyers and Family Leadership:")
print(avg_probs)

print("Average Predicted Probabilities by Expected Buyers and Town:")
print(avg_probs_town)

print("Overall Average Predicted Probabilities by Expected Buyers:")
print(overall_avg_probs)

# Calculate the overall sample storage rate
overall_storage_rate <- mean(data$storage_usage_binary, na.rm = TRUE)
print(paste("Overall Sample Storage Rate:", overall_storage_rate))


# Create a visualization of the overall average probabilities
plot1 <- ggplot(overall_avg_probs, aes(x = expect_3_months, y = avg_prob)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_hline(yintercept = overall_storage_rate, linetype = "dashed", color = "red") +
  labs(title = "Average Predicted Probabilities by Expected Buyers",
       subtitle = paste("Overall Sample Storage Rate:", round(overall_storage_rate, 3)),
       x = "Expected Buyers",
       y = "Predicted Probability of Storage") +
  theme_minimal()

# Create a visualization by family leadership status
plot2 <- ggplot(avg_probs, aes(x = expect_3_months, y = avg_prob, fill = factor(family_ever_village_leader))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = overall_storage_rate, linetype = "dashed", color = "red") +
  labs(title = "Predicted Probabilities by Expected Buyers and Family Leadership",
       x = "Expected Buyers",
       y = "Predicted Probability of Storage",
       fill = "Family Leadership") +
  theme_minimal()

# Create a visualization by town
plot3 <- ggplot(avg_probs_town, aes(x = expect_3_months, y = avg_prob, fill = town)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = overall_storage_rate, linetype = "dashed", color = "red") +
  labs(title = "Predicted Probabilities by Expected Buyers and Town",
       x = "Expected Buyers",
       y = "Predicted Probability of Storage",
       fill = "Town") +
  theme_minimal() +
  theme(legend.position = "bottom")

# Save the plots
ggsave(here("figures","overall_predicted_probs.png"), plot1, width = 8, height = 5)
ggsave(here("figures","predicted_probs_by_family.png"), plot2, width = 8, height = 5)
ggsave(here("figures","predicted_probs_by_town.png"), plot3, width = 8, height = 5)

# Display the plots
print(plot1)
print(plot2)
print(plot3)
```

```{r Difference-from-Baseline Plot}
# Let's use bootstrap to calculate SE and CI for the overall average predicted probabilities

# Set seed for reproducibility
set.seed(123)

# Number of bootstrap iterations
n_boot <- 1000

# Create a matrix to store bootstrap results
boot_results <- matrix(NA, nrow = n_boot, ncol = 3)
colnames(boot_results) <- c("no_change", "fewer_buyers", "more_buyers")

# Perform bootstrap
for (i in 1:n_boot) {
  # Sample with replacement from the original data
  boot_indices <- sample(1:nrow(data), size = nrow(data), replace = TRUE)
  boot_data <- data[boot_indices, ]
  
  # Fit the model on the bootstrap sample
  boot_model <- glm(storage_usage_binary ~ expect_3_months + age + education_highest + 
                   family_ever_village_leader + CRRA_adjusted  + liquidity_constraint + factor(town), 
                   data = boot_data, family = binomial)
  
  # Create prediction dataset with all combinations
  boot_newdata <- expand.grid(
    expect_3_months = c("no_change", "fewer_buyers", "more_buyers"),
    age = mean(boot_data$age, na.rm = TRUE),
    education_highest = mean(boot_data$education_highest, na.rm = TRUE),
    family_ever_village_leader = unique(boot_data$family_ever_village_leader),
    CRRA_adjusted = mean(boot_data$CRRA_adjusted, na.rm = TRUE),
    liquidity_constraint = unique(boot_data$liquidity_constraint),
    town = unique(boot_data$town)
  )
  
  # Calculate predicted probabilities
  boot_newdata$predicted_prob <- predict(boot_model, boot_newdata, type = "response")
  
  # Calculate average predicted probabilities by expected buyers
  boot_avg_probs <- boot_newdata %>%
    group_by(expect_3_months) %>%
    summarize(avg_prob = mean(predicted_prob, na.rm = TRUE),
              .groups = 'drop')
  
  # Store results in the bootstrap matrix
  boot_results[i, "no_change"] <- boot_avg_probs$avg_prob[boot_avg_probs$expect_3_months == "no_change"]
  boot_results[i, "fewer_buyers"] <- boot_avg_probs$avg_prob[boot_avg_probs$expect_3_months == "fewer_buyers"]
  boot_results[i, "more_buyers"] <- boot_avg_probs$avg_prob[boot_avg_probs$expect_3_months == "more_buyers"]
}

# Calculate mean, SE, and 95% CI for each group
overall_results <- data.frame(
  expect_3_months = c("no_change", "fewer_buyers", "more_buyers"),
  avg_prob = colMeans(boot_results, na.rm = TRUE),
  se = apply(boot_results, 2, sd, na.rm = TRUE)
)

overall_results$CI_lower <- overall_results$avg_prob - 1.96 * overall_results$se
overall_results$CI_upper <- overall_results$avg_prob + 1.96 * overall_results$se

# Print overall_results
print(overall_results)


# Create LaTeX table
library(xtable)
latex_table <- xtable(overall_results, 
                     caption = "Predicted Probabilities of Storage by Expected Buyers",
                     label = "tab:predicted_probs",
                     digits = 3)


# Save overall_results to TEX file
print(latex_table, 
      file = here("tables", "predicted_probabilities.tex"),
      floating = TRUE,
      table.placement = "htbp",
      include.rownames = FALSE)


# Calculate differences from baseline (no_change)
overall_results$difference <- overall_results$avg_prob - overall_results$avg_prob[overall_results$expect_3_months == "no_change"]

# Calculate confidence intervals for the differences
# For the baseline category, the difference is 0 with 0 SE
# For other categories, we need to account for covariance

# Extract the bootstrap differences for each iteration
boot_diff <- matrix(NA, nrow = n_boot, ncol = 3)
colnames(boot_diff) <- c("no_change", "fewer_buyers", "more_buyers")

# Calculate differences for each bootstrap sample
for (i in 1:n_boot) {
  baseline_prob <- boot_results[i, "no_change"]
  boot_diff[i, "no_change"] <- 0  # Difference from itself is 0
  boot_diff[i, "fewer_buyers"] <- boot_results[i, "fewer_buyers"] - baseline_prob
  boot_diff[i, "more_buyers"] <- boot_results[i, "more_buyers"] - baseline_prob
}

# Calculate SE and CI for differences
diff_se <- apply(boot_diff, 2, sd, na.rm = TRUE)
overall_results$diff_se <- diff_se
overall_results$diff_CI_lower <- overall_results$difference - 1.96 * overall_results$diff_se
overall_results$diff_CI_upper <- overall_results$difference + 1.96 * overall_results$diff_se

# Filter out the baseline category for the difference plot
diff_results <- overall_results[overall_results$expect_3_months != "no_change", ]

# Create a Difference-from-Baseline Plot
diff_plot <- ggplot(diff_results, aes(x = expect_3_months, y = difference)) +
  geom_point(size = 4, color = 'darkblue') +
  geom_errorbar(aes(ymin = diff_CI_lower, ymax = diff_CI_upper), width = 0.2, color = 'darkred') +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'black') +
  labs(title = 'Difference-from-Baseline Plot',
       subtitle = 'Predicted Probability Changes Relative to "No Change"',
       x = 'Expected Buyers Category',
       y = 'Difference in Predicted Probability of Storage') +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 20),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(size = 18),
    panel.border = element_rect(color = "black", fill = NA, size = 1)
  )

# Save the plot
ggsave(here("figures","filtered_difference_from_baseline_plot.png"), diff_plot, width = 8, height = 8, dpi = 300)

# Print the difference results
print(diff_results[, c("expect_3_months", "difference", "diff_se", "diff_CI_lower", "diff_CI_upper")])

# Display the plot
print(diff_plot)
```

```{r Correlation Matrix of Controls}
# Load the new package and re-run correlation matrix plot
library(ggcorrplot)

df <- read_excel(here("data","combined_updated.xlsx"))
# Extract control variables
control_vars <- df[, c("age", "education_highest", "family_ever_village_leader", "CRRA_adjusted", "liquidity_constraint", "num_buyers", "subjective_belief_buyer_com")]

# Calculate correlation matrix
cor_matrix <- cor(control_vars, use = "complete.obs")

# Visualize the correlation matrix
cor_plot <- ggcorrplot(cor_matrix, 
                      lab = TRUE, 
                      lab_size = 3,
                      colors = c("#6D9EC1", "white", "#E46726"),
                      title = "Correlation Matrix of Control Variables",
                      ggtheme = theme_minimal())

# Save the plot
ggsave(filename = here("figures", "correlation_matrix_controls.png"), plot = cor_plot, width = 6, height = 5, dpi = 300)

# Print the plot
print(cor_plot)
```

# Hazard Models with AFT parametrization

```{r baseline AFT}
# Load required libraries and data
library(survival)

data$lower_bound_weeks <- as.numeric(data$lower_bound)
data$upper_bound_weeks <- as.numeric(data$upper_bound)
storage_users <- subset(data, storage_usage_binary == 1)

# Run all models in one go
models <- list(
  # Full Sample Binary
  survreg(Surv(lower_bound_weeks, upper_bound_weeks, type="interval2") ~ 
          more_buyers_future + less_buyers_future + factor(town), 
          data = data, dist = "weibull"),
  
  # Storage Users Binary
  survreg(Surv(lower_bound_weeks, upper_bound_weeks, type="interval2") ~ 
          more_buyers_future + less_buyers_future + factor(town), 
          data = storage_users, dist = "weibull"),
  
  # Full Sample Continuous
  survreg(Surv(lower_bound_weeks, upper_bound_weeks, type="interval2") ~ 
          expected_number_of_buyers_in_3_months + factor(town), 
          data = data, dist = "weibull"),
  
  # Storage Users Continuous
  survreg(Surv(lower_bound_weeks, upper_bound_weeks, type="interval2") ~ 
          expected_number_of_buyers_in_3_months + factor(town), 
          data = storage_users, dist = "weibull")
)

# Capture the stargazer output as text
tex_table <- capture.output(
  stargazer(models, omit = "town", float = FALSE,
            digits = 2,
            font.size = "footnotesize", 
            title = "Weibull Survival Models of Market Timing Decisions",
            covariate.labels = c("More Buyers Expected", "Less Buyers Expected",
                                 "Expected Number of Buyers"),
            add.lines = list(c("Town Fixed Effects", "Yes", "Yes", "Yes", "Yes")),
            type = "latex")
)

# Wrap the stargazer output in a resizebox environment so it fits the page
resized_table <- c(
  "\\begin{table}[!htbp] \\centering",
  "\\label{tab: Survival AFT baseline}",
  "\\resizebox{\\textwidth}{!}{%",
  tex_table,
  "}",
  "\\end{table}"
)

# Write the table to the .tex file
out_path <- here("tables", "Weibull_Survival_Model_basic.tex")
writeLines(resized_table, out_path)
```

```{r extended AFT with controls}
# Split the data into full sample and storage users
full_sample <- data
storage_users <- subset(data, storage_usage_binary == 1)


# Check if datasets are loaded
if (!exists("full_sample") || !exists("storage_users")) {
  cat("Datasets 'full_sample' and 'storage_users' are not loaded. Please provide the data.")
} else {
  # Estimate models
  model_full <- survreg(Surv(time = lower_bound_weeks, time2 = upper_bound_weeks, type = 'interval2') ~ 
                        more_buyers_future + less_buyers_future + family_ever_village_leader + liquidity_constraint  +
                        far_to_small_storage + far_to_large_storage + storage_purpose_wider_marketing + 
                        storage_purpose_bargaining_tool + education_highest + num_buyers + 
                        factor(town), data = full_sample, dist = "weibull")

  model_storage <- survreg(Surv(time = lower_bound_weeks, time2 = upper_bound_weeks, type = 'interval2') ~ 
                           more_buyers_future + less_buyers_future + family_ever_village_leader + liquidity_constraint +
                           far_to_small_storage + far_to_large_storage + storage_purpose_wider_marketing + 
                           storage_purpose_bargaining_tool + education_highest + num_buyers + 
                           factor(town), data = storage_users, dist = "weibull")

# Generate LaTeX table using stargazer
stargazer(model_full, model_storage, type = "text", 
          label = "tab: extended Survival AFT with controls",
          add.lines = list(c("Town Fixed Effects", "Yes", "Yes")),omit = "town",digits = 2,
            title = "Extended Weibull Survival Models with Controls",
          font.size = "footnotesize", 
          dep.var.labels = "Time to Sell",
            column.labels = c("Full Sample", "Storage Users"),
            covariate.labels = c("More Buyers Future", "Less Buyers Future", "Family Village Leader", "Liquidity Constrained",
                                 "Far to Small Storage", "Far to Large Storage", "Storage Purpose: Marketing",
                                 "Storage Purpose: Bargaining", "Education Level", "Number of Buyers"),
            out = here("tables", "Extended_Weibull_Survival_Models_with_Controls.tex"))
}
```



# Buyer Count Distribution
```{r}
data_df <- df
# Create expectation category
data_df <- data_df %>%
  mutate(
    expectation = case_when(
      more_buyers_future == 1 ~ 'More buyers',
      less_buyers_future == 1 ~ 'Fewer buyers',
      TRUE ~ 'No change'
    )
  )

# Summarize counts and percentages
summary_df <- data_df %>%
  group_by(num_buyers, expectation) %>%
  summarise(count = n(), .groups='drop') %>%
  group_by(num_buyers) %>%
  mutate(perc = count / sum(count)) %>%
  ungroup()

# Plot stacked bar chart
colors_vec <- c('More buyers' = 'darkgreen',
                'Fewer buyers' = 'darkred',
                'No change' = '#bdbdbd')

stack_plot <- ggplot(summary_df, aes(x = factor(num_buyers, levels = sort(unique(num_buyers))),
                                     y = count,
                                     fill = expectation)) +
  geom_col(color='white') +
  scale_fill_manual(values = colors_vec, name='Expectation about Future') +
  labs(
    title = "Farmers’ Expectations About Future Buyers by Observed Buyer Count at Harvest",
    x = 'Number of Buyers Observed at Harvest',
    y = 'Number of Farmers') +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size=10),
    axis.title = element_text(size=8),
    legend.title = element_text(size=8),
    legend.text = element_text(size=8)
  )

# Add percentage labels if the segment is large enough (>5%)
stack_plot <- stack_plot +
  geom_text(aes(label = ifelse(perc >= 0.05, paste0(round(perc*100), '%'), '')),
            position = position_stack(vjust = 0.5),
            size = 2, color = 'white')

# Display table and plot
print(head(summary_df))
print(stack_plot)


# Save the plot
ggsave(filename = here("figures", "buyer_count_distribution.png"), plot = stack_plot, width = 6, height = 3, dpi = 300)
```










